Used anywhere AI outputs are presented, to give the user a way to flag poor quality outputs

<div><img src="/public/images/cps/reportIssue1.png" alt="Example report an issue summary " style="width:100%;height:auto"></div>
<div><img src="/public/images/cps/reportIssue2.png" alt="Example from the disproportionality use case" style="width:100%;height:auto"></div>

## Where

During a task, once the AI outputs have been generated

## Mindful friction could help

- Reinforce the need to use human judgement
- Build trust in the system
- Provide an input for monitoring quality, and further training data

## Risks this pattern could mitigate

- Automation complacency
- Skills fade
- Outputs becoming lower quality over time

## Donâ€™ts

- Ask for feedback that is too detailed for its context, ideally it should be very easy to do
- Fail to follow up, as it will create mistrust in the system and make leaving feedback seem pointless


## Needs testing

- What are the types of feedback relevant for different types of outputs
- What should happen immediately upon reporting, for the user and for the whole system
- What are the governance and monitoring capabilities needed to maintain or increase the quality of outputs